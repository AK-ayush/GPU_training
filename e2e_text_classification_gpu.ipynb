{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nvstrings\n",
    "import nvcategory\n",
    "import cudf\n",
    "import numpy as np\n",
    "from numba import cuda, float32\n",
    "import ctypes\n",
    "import math\n",
    "import cupy\n",
    "import time \n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400000, 50)\n",
      "float32\n",
      "0    the\n",
      "1      ,\n",
      "2      .\n",
      "3     of\n",
      "4     to\n",
      "5    and\n",
      "6     in\n",
      "7      a\n",
      "8      \"\n",
      "9     's\n",
      "[399990 more rows]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "pre_df = cudf.read_csv(\"datasets/glove.6B.50d.txt\", header=None, delim_whitespace=True, quoting=3)  #ignore quoting\n",
    "\n",
    "mappings = pre_df['0']\n",
    "\n",
    "pre_df.drop_column('0')\n",
    "for c in pre_df.columns:\n",
    "    pre_df[c] = pre_df[c].astype(np.float32)\n",
    "mat = pre_df.as_gpu_matrix()\n",
    "\n",
    "print(mat.shape)\n",
    "print(mat.dtype)\n",
    "print(mappings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit(device=True)\n",
    "def dot(a, b, dim_size):\n",
    "    summ = 0\n",
    "    for i in range(dim_size):\n",
    "        summ += (a[i]*b[i])\n",
    "    return summ\n",
    "\n",
    "@cuda.jit(device=True)\n",
    "def cosine_sim(a, b, dim_size):\n",
    "    return dot(a,b, dim_size) / ( math.sqrt(dot(a, a, dim_size)) * math.sqrt(dot(b, b, dim_size)) )\n",
    "\n",
    "@cuda.jit('void(float32[:,:], int32[:], int32, int32)')\n",
    "def find_nearest(mat, out, dim_size, n):\n",
    "    idx = cuda.threadIdx.x + cuda.blockDim.x * cuda.blockIdx.x\n",
    "    if idx >= n:\n",
    "        return\n",
    "    c = -1.0 \n",
    "    c_i = idx\n",
    "    # here is room for improvement using shared memory \n",
    "    for i in range(n):\n",
    "        if i == idx:\n",
    "            continue\n",
    "        csim = cosine_sim(mat[idx], mat[i], dim_size)\n",
    "        if csim >= c:\n",
    "            c_i = i\n",
    "            c = csim\n",
    "    \n",
    "    out[idx] = c_i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel launch configuraion:  128 3125\n",
      "time taken 4.021586120128632 mins\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>nearest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>,</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>which</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "      <td>take</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>in</td>\n",
       "      <td>from</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>a</td>\n",
       "      <td>another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\"</td>\n",
       "      <td>“</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'s</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>for</td>\n",
       "      <td>making</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>that</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>on</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>is</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>was</td>\n",
       "      <td>later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>said</td>\n",
       "      <td>told</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>with</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>he</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>as</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    word  nearest\n",
       "0    the    which\n",
       "1      ,        .\n",
       "2      .     same\n",
       "3     of    which\n",
       "4     to     take\n",
       "5    and     well\n",
       "6     in     from\n",
       "7      a  another\n",
       "8      \"        “\n",
       "9     's      has\n",
       "10   for   making\n",
       "11     -       --\n",
       "12  that      but\n",
       "13    on   before\n",
       "14    is     this\n",
       "15   was    later\n",
       "16  said     told\n",
       "17  with      and\n",
       "18    he      his\n",
       "19    as     also"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = mat.shape[0]\n",
    "dim_size = mat.shape[1]\n",
    "device = cuda.get_current_device()\n",
    "\n",
    "tpb = 128 #device.WARP_SIZE    #blocksize or thread per block\n",
    "bpg = int(np.ceil((n)/tpb))  # block per grid\n",
    "print( \"kernel launch configuraion: \", tpb, bpg)\n",
    "\n",
    "out = cuda.device_array(shape=n, dtype=np.int32)\n",
    "\n",
    "st = time.time()\n",
    "find_nearest[bpg,tpb](mat, out, dim_size, n)\n",
    "cuda.synchronize()\n",
    "\n",
    "print(\"time taken {} mins\".format((time.time()-st)/60))\n",
    "\n",
    "result_df = cudf.DataFrame({'word':mappings})\n",
    "result_df['nearest']= mappings.iloc[out]\n",
    "\n",
    "result_df.head(20).to_pandas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del result_df, mat, out\n",
    "pre_df['0'] = mappings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sents(gstr):\n",
    "    gstr = gstr.replace(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \")\n",
    "    gstr = gstr.replace(r\"\\'s\", \" \\'s\")\n",
    "    gstr = gstr.replace(r\"\\'ve\", \" \\'ve\")\n",
    "    gstr = gstr.replace(r\"n\\'t\", \" n\\'t\")\n",
    "    gstr = gstr.replace(r\"\\'re\", \" \\'re\")\n",
    "    gstr = gstr.replace(r\"\\'d\", \" \\'d\")\n",
    "    gstr = gstr.replace(r\"\\'ll\", \" \\'ll\")\n",
    "    gstr = gstr.replace(r\",\", \" , \")\n",
    "    gstr = gstr.replace(r\"!\", \" ! \")\n",
    "    gstr = gstr.replace(r\"\\(\", \" \\( \")\n",
    "    gstr = gstr.replace(r\"\\)\", \" \\) \")\n",
    "    gstr = gstr.replace(r\"\\?\", \" \\? \")\n",
    "    gstr = gstr.replace(r\"\\s{2,}\", \" \")\n",
    "    return gstr.strip().lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = cudf.read_csv(\"/a0k00jd/datasets/train.csv\", quoting=3, skiprows=1, names=['review', 'label'])\n",
    "y_train = sents['label'].astype('float32').to_gpu_array()\n",
    "gstr = sents['review'].data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "2707\n"
     ]
    }
   ],
   "source": [
    "MAX_LEN = 20\n",
    "num_sents = gstr.size()\n",
    "gstr = clean_sents(gstr)\n",
    "\n",
    "#generate the tokens\n",
    "seq = gstr.split_record(' ')\n",
    "\n",
    "for i in range(len(seq)):\n",
    "    l = seq[i].size()\n",
    "    seq[i] = seq[i].add_strings(nvstrings.to_device((MAX_LEN-l)*['PAD'])) if l <=MAX_LEN else seq[i].remove_strings(list(range(MAX_LEN,l)))\n",
    "\n",
    "#generating the indices corresponding each token \n",
    "c = nvcategory.from_strings_list(seq)\n",
    "print(len(c.values()))\n",
    "print(len(c.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      tokens\n",
      "0         !\n",
      "1    'cover\n",
      "2        'd\n",
      "3    'film'\n",
      "4       'll\n",
      "5    'must'\n",
      "6       're\n",
      "7        's\n",
      "8       'so\n",
      "9  'stagey'\n",
      "[2697 more rows]\n",
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# generating unique tokens \n",
    "# print(c.keys())\n",
    "sent_df = cudf.DataFrame({'tokens':c.keys()})\n",
    "print(sent_df)\n",
    "\n",
    "# preparing the X_train \n",
    "X_train = cuda.device_array((num_sents, MAX_LEN), dtype=np.float32)\n",
    "c.values(X_train.device_ctypes_pointer.value)\n",
    "print(X_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2707\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "vocab_df = sent_df.merge(pre_df,left_on='tokens', right_on='0', how='left')\n",
    "vocab_df.drop_column('0')\n",
    "vocab_df.drop_column('tokens')\n",
    "\n",
    "all_token = vocab_df.shape[0]\n",
    "print(all_token)\n",
    "#calculating the number of tken not found in GloVe \n",
    "not_found = vocab_df['1'].null_count\n",
    "print(not_found)\n",
    "\n",
    "# filling the not found tokens with random vector, [now with -1]\n",
    "for c in vocab_df.columns:\n",
    "    vocab_df[c] = vocab_df[c].fillna(cupy.random.normal(size=all_token)).astype(np.float32)\n",
    "vocab = vocab_df.as_gpu_matrix(order='C')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    num_embeddings, embedding_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    # emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "    emb_layer.weight = nn.Parameter(weights_matrix)\n",
    "    if non_trainable:\n",
    "        emb_layer.weight.requires_grad = False\n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim\n",
    "\n",
    "class ToyLSTM(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_size, output_size, num_layers):\n",
    "        super(ToyLSTM, self).__init__()\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "         \n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, hidden_size//2)\n",
    "        self.out = nn.Linear(hidden_size//2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, inp):\n",
    "        h_embedding = self.embedding(inp) \n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        max_pool, _ = torch.max(h_lstm, 1)\n",
    "        linear = self.relu(self.linear(max_pool)) \n",
    "        out = self.out(linear) \n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def devndarray2tensor(dev_arr, dtyp='float32'):\n",
    "    dmap = {'float32':torch.float32, 'long':torch.long}\n",
    "    t = torch.empty(size=dev_arr.shape, dtype=dmap[dtyp]).cuda()\n",
    "    ctx = cuda.cudadrv.driver.driver.get_context()\n",
    "    \n",
    "    # constant value of #bytes in float32 = 4\n",
    "    mp = cuda.cudadrv.driver.MemoryPointer(ctx, ctypes.c_ulong(t.data_ptr()), t.numel()*4)\n",
    "    tmp_arr = cuda.cudadrv.devicearray.DeviceNDArray(t.size(), [i*4 for i in t.stride()], np.dtype(dtyp), \n",
    "                                            gpu_data=mp, stream=torch.cuda.current_stream().cuda_stream)\n",
    "    tmp_arr.copy_to_device(dev_arr)\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ToyLSTM(\n",
       "  (embedding): Embedding(2707, 50)\n",
       "  (lstm): LSTM(50, 10, num_layers=3, batch_first=True)\n",
       "  (linear): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (out): Linear(in_features=5, out_features=1, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_lstm = ToyLSTM(weights_matrix=devndarray2tensor(vocab), hidden_size=10, output_size=1, num_layers=3).cuda()\n",
    "toy_lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'F_CONTIGUOUS': True, 'C_CONTIGUOUS': True}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.flags\n",
    "y_train.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = TensorDataset(devndarray2tensor(X_train).to(torch.int64), devndarray2tensor(y_train))\n",
    "trainloader = DataLoader(train, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "optimizer = optim.Adam(toy_lstm.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 10):\n",
    "    train_loss, valid_loss = [], []\n",
    "\n",
    "    # training part\n",
    "    toy_lstm.train()\n",
    "    for data, target in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = toy_lstm(data)\n",
    "        loss = loss_function(output, target.view(-1,1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss.append(loss.item())\n",
    "    \n",
    "    ## evaluation part \n",
    "    toy_lstm.eval()\n",
    "    for data, target in trainloader:\n",
    "        output = toy_lstm(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6914850473403931,\n",
       " 0.6998982429504395,\n",
       " 0.6914698481559753,\n",
       " 0.6933820843696594,\n",
       " 0.6966598033905029,\n",
       " 0.69050133228302,\n",
       " 0.692365288734436,\n",
       " 0.6894925236701965]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
